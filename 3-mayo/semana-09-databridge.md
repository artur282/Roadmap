# ğŸŒ‰ Semana 09 â€” DataBridge

> **Pipeline ETL completo con validaciÃ³n, transformaciÃ³n y carga entre sistemas**

| Campo              | Detalle                       |
| ------------------ | ----------------------------- |
| ğŸ“… Fechas          | 2-3 de mayo 2026              |
| ğŸ·ï¸ CategorÃ­a       | Data Engineering & Automation |
| â±ï¸ Tiempo estimado | 10-12 horas                   |
| ğŸ“Š Dificultad      | â­â­â­ Intermedio             |

---

## ğŸ¯ DescripciÃ³n

DataBridge es un pipeline ETL (Extract, Transform, Load) profesional que migra datos entre diferentes fuentes: archivos CSV/JSON, bases SQLite y PostgreSQL. Incluye validaciÃ³n de datos, transformaciones configurables, manejo de errores con rollback, logging detallado y reportes de ejecuciÃ³n.

Simula un escenario real de migraciÃ³n de datos empresariales â€” una de las tareas mÃ¡s comunes y crÃ­ticas en ingenierÃ­a de datos.

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Pipeline ETL                       â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ EXTRACT  â”‚â”€â”€â”€â–¶â”‚TRANSFORM â”‚â”€â”€â”€â–¶â”‚   LOAD   â”‚       â”‚
â”‚  â”‚          â”‚    â”‚          â”‚    â”‚          â”‚       â”‚
â”‚  â”‚ â€¢ CSV    â”‚    â”‚ â€¢ Clean  â”‚    â”‚ â€¢ PostgreSQLâ”‚     â”‚
â”‚  â”‚ â€¢ JSON   â”‚    â”‚ â€¢ Validateâ”‚   â”‚ â€¢ Batch   â”‚     â”‚
â”‚  â”‚ â€¢ SQLite â”‚    â”‚ â€¢ Convert â”‚   â”‚ â€¢ Upsert  â”‚     â”‚
â”‚  â”‚ â€¢ API    â”‚    â”‚ â€¢ Enrich  â”‚   â”‚ â€¢ Rollbackâ”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚       â”‚               â”‚               â”‚              â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                       â”‚                              â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚              â”‚   Orchestrator   â”‚                     â”‚
â”‚              â”‚   (Pipeline      â”‚                     â”‚
â”‚              â”‚    Manager)      â”‚                     â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                       â”‚                              â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚       â”‚               â”‚               â”‚              â”‚
â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Logger  â”‚    â”‚ Reporterâ”‚    â”‚ Monitor â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Features

### Extract (ExtracciÃ³n)

- [ ] Lectura de archivos CSV con diferentes encodings
- [ ] Lectura de archivos JSON y JSON Lines
- [ ] ExtracciÃ³n desde SQLite
- [ ] ExtracciÃ³n desde APIs REST
- [ ] Lectores configurables y extensibles

### Transform (TransformaciÃ³n)

- [ ] Limpieza de datos (nulls, duplicados, whitespace)
- [ ] ValidaciÃ³n con schemas (Pydantic/Pandera)
- [ ] ConversiÃ³n de tipos de datos
- [ ] NormalizaciÃ³n de campos (fechas, monedas, emails)
- [ ] Enriquecimiento (campos calculados)
- [ ] Transformaciones configurables por YAML

### Load (Carga)

- [ ] Carga a PostgreSQL
- [ ] InserciÃ³n batch (bulk insert)
- [ ] Upsert (insert or update)
- [ ] Transacciones con rollback en caso de error
- [ ] ExportaciÃ³n a CSV/JSON (alternativa)

### OrquestaciÃ³n

- [ ] Pipeline configurable por YAML
- [ ] EjecuciÃ³n por CLI
- [ ] Logging detallado (por paso y por fila)
- [ ] Reporte de ejecuciÃ³n (filas procesadas, errores, duraciÃ³n)
- [ ] Modo dry-run (validar sin cargar)

---

## ğŸ› ï¸ Stack tÃ©cnico

| TecnologÃ­a         | PropÃ³sito                 |
| ------------------ | ------------------------- |
| **Python 3.11+**   | Lenguaje base             |
| **Pandas**         | Procesamiento de datos    |
| **Pandera**        | ValidaciÃ³n de schemas     |
| **SQLAlchemy**     | ConexiÃ³n a bases de datos |
| **PostgreSQL**     | Destino principal         |
| **SQLite**         | Fuente de ejemplo         |
| **Typer**          | CLI                       |
| **Rich**           | VisualizaciÃ³n de progreso |
| **Docker Compose** | Infraestructura           |
| **pytest**         | Testing                   |

---

## ğŸ—“ï¸ Plan del fin de semana

### SÃ¡bado

| Hora           | Actividad                                       |
| -------------- | ----------------------------------------------- |
| ğŸŒ… 9:00-10:00  | Setup, Docker Compose, estructura               |
| ğŸŒ… 10:00-12:00 | Extractores: CSV, JSON, SQLite                  |
| ğŸŒ 12:00-13:00 | Transformadores: limpieza, validaciÃ³n           |
| ğŸŒ 14:00-16:00 | Transformadores: normalizaciÃ³n, enriquecimiento |
| ğŸŒ† 16:00-18:00 | Loaders: PostgreSQL (batch + upsert)            |

### Domingo

| Hora           | Actividad                                  |
| -------------- | ------------------------------------------ |
| ğŸŒ… 9:00-10:30  | Pipeline orchestrator + configuraciÃ³n YAML |
| ğŸŒ… 10:30-12:00 | CLI + modo dry-run                         |
| ğŸŒ 13:00-14:30 | Logging, reportes de ejecuciÃ³n             |
| ğŸŒ 14:30-16:00 | Tests con datasets de ejemplo              |
| ğŸŒ† 16:00-17:00 | README con ejemplos y diagramas            |

---

## âœ… DefiniciÃ³n de "hecho"

- [ ] Pipeline funcional CSV â†’ Transform â†’ PostgreSQL
- [ ] Al menos 3 extractores y 5 transformadores
- [ ] ValidaciÃ³n de datos con reporte de errores
- [ ] CLI con modo normal y dry-run
- [ ] Tests con datasets fixture
- [ ] Docker Compose funcional
- [ ] README con ejemplos y configuraciÃ³n

---

## ğŸ’¼ Lo que demuestra al reclutador

| Habilidad    | Evidencia                                    |
| ------------ | -------------------------------------------- |
| ETL          | Pipeline completo extract â†’ transform â†’ load |
| Datos        | Pandas, validaciÃ³n, limpieza a escala        |
| SQL          | PostgreSQL, batch insert, upsert             |
| Arquitectura | Pipeline pattern, plugins, configuraciÃ³n     |
| ProducciÃ³n   | Logging, rollback, reportes                  |
